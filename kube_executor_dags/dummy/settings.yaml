# Стенд, на котором исполняется расчёт
stand: localhost_docker
# Хаб
hub: RB
# Уникальное имя проекта
project_name: dummy_feature_repo
# Описание проекта (опционально)
project_description: "Простой пример"
author_name: 'Alexey Golovizin'
author_email: 'AGolovizin@alfabank.ru'

# Настройки таблиц-источников в Hadoop: словарь, ключи которого -- короткие мнемонические имена таблиц-источников.
# В шаблонах мы будем обращаться к таблицам по этим именам.
src_settings:
  default_schema_name: tech_profiling

  default_pre_checks:

#    - check_type: "min_not_null_on_date"
#      params:
#        min_not_null_rows: 50_000
#        column: client_pin
#    - check_type: "date_partition_exists"
#      params:
#        date_policy: first_day_of_month

  tables:
    sinner_souls:
      table_name: neural_example__sinner_souls


# Настройки выходных таблиц в Hadoop
dest_settings:
  default_schema_name: tech_profiling
  calculate_metrics: false

#  default_pre_checks:
#    - check_type: "table_exists"

  default_metrics:
    - metrics_type: min
    - metrics_type: average

  default_datamart_metrics:
    - metrics_type: "partition_size"

save_metadata: false

spark_settings:
  default:
    # Настройки HADOOP (аналогично $HADOOP_CONF_DIR, но поддерживается и относительный путь от ETL-репозитория)
#     hadoop_conf_dir: "../_hadoop_configs/quickstart-bigdata-configs"
    # Подставить заданный $HADOOP_USER_NAME
    hadoop_user_name: osboxes
    # Если true, то создаст удалённую Spark-сессию с .master("yarn")
    use_yarn_master: false
  #   use_kerberos: true
    extra_configs:
      "hive.exec.dynamic.partition.mode": nonstrict


task_class_settings:
  default:
    spark_profile: default
    pypi_repo_settings:
      index_url: https://artapp.moscow.alfaintra.net/artifactory/api/pypi/pypi-remote/simple
      trusted_hosts:
      - artapp.moscow.alfaintra.net
      - binary.alfabank.ru
      extra_index_urls:
        - https://binary.alfabank.ru/artifactory/api/pypi/fs_etl_test/simple
    kubernetes_settings:
      image:
      memory_limit: 4000Mi
      cpu_limit: 2000m
      memory_request: 500Mi
      cpu_request: 500m



# Дополнительные переменные среды перед запуском ETL-процесса
env_vars:
#   PYSPARK_PYTHON: python3


# Дополнительные настройки: в словарь верхнего уровня можно добавлять YAML-объекты произвольной структуры
multiline_example_settings:
  schema_name: "hell"
  create_schema: false